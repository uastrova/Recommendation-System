{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Рекомендательная система | CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка проблемы\n",
    "\n",
    "Во многих социальных сетях есть лента, которую пользователи могут прокручивать и просматривать случайные посты из разных сообществ. А что, если показывать пользователям не случайные посты, а рекомендовать их каждому пользователю из всего набора постов? Как это сделать и учесть индивидуальные особенности профиля пользователя, его прошлую активность и содержание самих постов? Моей задачей было построить систему рекомендаций для постов в социальной сети. В качестве основных исходных данных я использовала заранее подготовленные таблицы из базы данных \"Karpov courses\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн проекта:\n",
    "\n",
    "**1) Загрузка данных из базы данных (БД) и обзор данных**\n",
    "\n",
    "   Подключиться к базе данных, выгрузаить необходимые данные для анализа. Цель — понять структуру данных, выявить возможные пропуски или аномалии, а также получить общее представление о распределении и составе данных. Анализ включает изучение признаков (features) и целевой переменной.\n",
    "   \n",
    "**2) Создание признаков и формирование обучающей выборки**\n",
    "\n",
    "На этом этапе я создаю новые признаки, которые могут быть полезны для модели. После генерации признаков формируется обучающая выборка, которая содержит все необходимые данные для последующего обучения модели.\n",
    "\n",
    "**3) Тренировка модели и оценка её качества**\n",
    "\n",
    "Используя обучающую выборку, я обучаю модель, выбирая алгоритм и его параметры. После обучения настраиваю модель и проверяю её качество на валидационной выборке. \n",
    "\n",
    "**4) Сохранение обученной модели**\n",
    "\n",
    "**5) Разработка сервиса для использования модели** \n",
    "\n",
    "Здесь я создаю сервис, который позволит взаимодействовать с моделью в реальном времени. Сервис включает следующие шаги:\n",
    "\n",
    "* Загрузка модели: при запуске сервис загружает ранее сохранённую модель из файла.\n",
    "* Получение признаков: сервис принимает запросы с user_id, на основе которого формирует нужные признаки для предсказания или загружаются уже с таблиц, которые вы загрузили в базу данных КарповКурсес. Признаки в момент предсказания должны совпадать с признаками, которые были в момент обучения модели.\n",
    "* Предсказание: используя загруженную модель и полученные признаки, сервис делает предсказание — определяет посты, которые, вероятно, понравятся пользователю.\n",
    "* Возвращение ответа: сервис возвращает ответ с результатами предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание данных**\n",
    "\n",
    "Данные хранятся в базе данных в таблицах:\n",
    "1. **'user data'** - содержит информацию о всех пользователях соц.сети\n",
    "   * age\tВозраст пользователя (в профиле)\n",
    "   * city\tГород пользователя (в профиле)\n",
    "   * country\tСтрана пользователя (в профиле)\n",
    "   * exp_group\tЭкспериментальная группа: некоторая зашифрованная категория\n",
    "   * gender\tПол пользователя\n",
    "   * user_id  Уникальный идентификатор пользователя\n",
    "   * os\tОперационная система устройства, с которого происходит пользование соц.сетью\n",
    "   * source\tПришел ли пользователь в приложение с органического трафика или с рекламы\n",
    "2. **'post_text_df'** - содержит информацию о постах и уникальный ID каждой единицы с соответствующим ей текстом и топиком\n",
    "   * id\tУникальный идентификатор поста\n",
    "   * text\tТекстовое содержание поста\n",
    "   * topic\tОсновная тематика\n",
    "3. **'feed_data'** - Содержит историю о просмотренных постах для каждого юзера в изучаемый период.\n",
    "   * timestamp\tВремя, когда был произведен просмотр\n",
    "   * user_id\tid пользователя, который совершил просмотр\n",
    "   * post_id\tid просмотренного поста\n",
    "   * action\tТип действия: просмотр или лайк\n",
    "   * target\t1 у просмотров, если почти сразу после просмотра был совершен лайк, иначе 0. У действий like пропущенное значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы создать датафрейм, я использую SQL-запросы к базе данных PostgreSQL.'feed_data' - большая таблица, поэтому не загружаем её полностью. \n",
    "В 'feed_data' строки упорядочены по временным меткам действий, поэтому id одного пользователя может встречаться много раз подряд. Также распределение целевой переменной неравномерно, поэтому я обращаюсь к 'feed_data' двумя запросами, с помощью которых получаю уникальную информацию о всех пользователях и уменьшаю неравномерность распределения целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:49:43.945984Z",
     "iopub.status.busy": "2025-04-20T15:49:43.945642Z",
     "iopub.status.idle": "2025-04-20T15:49:54.953791Z",
     "shell.execute_reply": "2025-04-20T15:49:54.952631Z",
     "shell.execute_reply.started": "2025-04-20T15:49:43.945940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "database=\"startml\",\n",
    "user=\"robot-startml-ro\",\n",
    "password=\"pheiph0hahj1Vaif\",\n",
    "host=\"postgres.lab.karpov.courses\",\n",
    "port=6432\n",
    "conn_uri = \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@postgres.lab.karpov.courses:6432/startml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на 'feed_data'. Строки таблицы упорядочены по временным меткам, поэтому id одного пользователя встречается много раз подряд. Таблица большая, поэтому загружаю её не полностью - чтобы при этом точно получить информацию о всех пользователях создаю 'extra_data'.\n",
    "Также распределение целевой переменной неравномерно, поэтому я создаю еще один датафрейм с рандомными 1000000 строками и target=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:14:33.181974Z",
     "iopub.status.busy": "2025-04-20T15:14:33.181561Z",
     "iopub.status.idle": "2025-04-20T15:14:37.509417Z",
     "shell.execute_reply": "2025-04-20T15:14:37.507890Z",
     "shell.execute_reply.started": "2025-04-20T15:14:33.181938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  user_id  post_id action  target\n",
      "0 2021-10-25 10:01:02     3090     6955   view       0\n",
      "1 2021-10-25 10:03:18     3090     3133   view       0\n",
      "2 2021-10-25 10:03:45     3090     4550   view       0\n",
      "3 2021-10-25 10:04:45     3090     4278   view       0\n",
      "4 2021-10-25 10:06:49     3090     4034   view       0\n",
      "target\n",
      "0    89516\n",
      "1    10484\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feed_data_overview = pd.read_sql(\"SELECT * FROM public.feed_data limit 100000;\", conn_uri)\n",
    "print(feed_data_overview.head())\n",
    "print(feed_data_overview['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_df = pd.read_sql(\"SELECT * FROM public.user_data;\", conn_uri)\n",
    "post_text_df = pd.read_sql(\"SELECT * FROM public.post_text_df;\", conn_uri)\n",
    "extra_data = pd.read_sql(\"SELECT distinct on (user_id, target,feed_data.action,target) timestamp,user_id,post_id,public.feed_data.action,target FROM public.feed_data;\", conn_uri)\n",
    "feed_data = pd.read_sql(\"SELECT * FROM public.feed_data where target=1 order by random()limit 1000000;\", conn_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:24:10.556279Z",
     "iopub.status.busy": "2024-11-24T07:24:10.555248Z",
     "iopub.status.idle": "2024-11-24T07:24:11.534065Z",
     "shell.execute_reply": "2024-11-24T07:24:11.532975Z",
     "shell.execute_reply.started": "2024-11-24T07:24:10.556234Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_df = pd.concat([extra_data, feed_data], axis=0)\n",
    "df = pd.merge(user_df, extra_df, on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяю OneHotEncoding и MeanTarget для категориальных фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:24:13.076123Z",
     "iopub.status.busy": "2024-11-24T07:24:13.075746Z",
     "iopub.status.idle": "2024-11-24T07:24:16.400647Z",
     "shell.execute_reply": "2024-11-24T07:24:16.399735Z",
     "shell.execute_reply.started": "2024-11-24T07:24:13.076089Z"
    }
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# OneHotEncoding and MeanTarget for categorical features\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].nunique() < 5:\n",
    "        one_hot = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "        df = pd.concat((df.drop(col, axis=1), one_hot), axis=1)\n",
    "    else:\n",
    "        mean_target = df.groupby(col)['target'].mean()\n",
    "        df[col] = df[col].map(mean_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:24:30.081176Z",
     "iopub.status.busy": "2024-11-24T07:24:30.080333Z",
     "iopub.status.idle": "2024-11-24T07:24:30.216789Z",
     "shell.execute_reply": "2024-11-24T07:24:30.215655Z",
     "shell.execute_reply.started": "2024-11-24T07:24:30.081137Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df['exp_group'], prefix=col, drop_first=True)\n",
    "df = pd.concat((df.drop('exp_group', axis=1), pd.get_dummies(df['exp_group'], prefix=col, drop_first=True)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяю MeanTarget к 'age' а также создаю новую фичу - 'post_likes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:24:32.876271Z",
     "iopub.status.busy": "2024-11-24T07:24:32.875864Z",
     "iopub.status.idle": "2024-11-24T07:24:33.427981Z",
     "shell.execute_reply": "2024-11-24T07:24:33.426626Z",
     "shell.execute_reply.started": "2024-11-24T07:24:32.876234Z"
    }
   },
   "outputs": [],
   "source": [
    "# MeanTarget for 'age'\n",
    "mean_target_2 = df.groupby('age')['target'].mean()\n",
    "df['age'] = df['age'].map(mean_target_2)\n",
    "\n",
    "# Popularity of text\n",
    "df['post_likes'] = df.groupby('post_id')['target'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:30:21.527324Z",
     "iopub.status.busy": "2024-11-24T07:30:21.526922Z",
     "iopub.status.idle": "2024-11-24T07:31:23.464971Z",
     "shell.execute_reply": "2024-11-24T07:31:23.463788Z",
     "shell.execute_reply.started": "2024-11-24T07:30:21.527288Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:34:43.302165Z",
     "iopub.status.busy": "2024-11-24T07:34:43.301506Z",
     "iopub.status.idle": "2024-11-24T07:34:43.309706Z",
     "shell.execute_reply": "2024-11-24T07:34:43.308706Z",
     "shell.execute_reply.started": "2024-11-24T07:34:43.302109Z"
    }
   },
   "outputs": [],
   "source": [
    "#import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка текста постов для последующего создания TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:36:37.703473Z",
     "iopub.status.busy": "2024-11-24T07:36:37.703056Z",
     "iopub.status.idle": "2024-11-24T07:36:42.351283Z",
     "shell.execute_reply": "2024-11-24T07:36:42.350182Z",
     "shell.execute_reply.started": "2024-11-24T07:36:37.703435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clearing text\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Tokenization, stop word removal and lower case conversion\n",
    "sw = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()  \n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    \n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    # Function to remove emojis from text\n",
    "    def remove_emojis(text):\n",
    "        return emoji.demojize(text)\n",
    "   \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "post_text_df['text'] = post_text_df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 300)  \n",
    "tfidf_matrix = tfidf.fit_transform(post_text_df['text'].fillna('unknown'))\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "tfidf_df.reset_index(drop=True, inplace=True)\n",
    "post_text_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение StandardScaler, PCA и метода ближайших соседей к TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:37:01.955803Z",
     "iopub.status.busy": "2024-11-24T07:37:01.955409Z",
     "iopub.status.idle": "2024-11-24T07:37:03.200569Z",
     "shell.execute_reply": "2024-11-24T07:37:03.199530Z",
     "shell.execute_reply.started": "2024-11-24T07:37:01.955770Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(tfidf_df)\n",
    "\n",
    "# Применение PCA\n",
    "pca = PCA(n_components=50) \n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "X_pca= X_pca.add_prefix('PCA_')\n",
    "\n",
    "cluster_num = int((len(df))*0.05)\n",
    "kmeans = KMeans(n_clusters=100, random_state=42).fit(X_pca)\n",
    "scaler = StandardScaler()\n",
    "KMeans_scaled = scaler.fit_transform(X_pca)\n",
    "post_text_df['kmeans_pca'] = kmeans.predict(X=X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:37:19.343577Z",
     "iopub.status.busy": "2024-11-24T07:37:19.343162Z",
     "iopub.status.idle": "2024-11-24T07:37:19.869978Z",
     "shell.execute_reply": "2024-11-24T07:37:19.868880Z",
     "shell.execute_reply.started": "2024-11-24T07:37:19.343532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Новая фича - длина текста \n",
    "post_text_df['text_length'] = post_text_df['text'].apply(len)\n",
    "post_final = post_changed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Взаимодействие с топиками\n",
    "topic_interactions = feed_data.merge(post_text_df[['post_id', 'topic']], left_on='post_id', right_on='post_id', how='left')\n",
    "topic_interactions = topic_interactions.groupby(['user_id', 'topic']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:37:24.935072Z",
     "iopub.status.busy": "2024-11-24T07:37:24.934689Z",
     "iopub.status.idle": "2024-11-24T07:37:25.949135Z",
     "shell.execute_reply": "2024-11-24T07:37:25.948062Z",
     "shell.execute_reply.started": "2024-11-24T07:37:24.935039Z"
    }
   },
   "outputs": [],
   "source": [
    "df_catboost = pd.merge(df, topic_interactions, on='user_id', how='left')\n",
    "df_catboost = pd.merge(df_catboost, post_final, on='post_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding для 'country' и 'topic'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for column in ['country', 'topic']:\n",
    "    le = LabelEncoder()\n",
    "    df_catboost[column] = le.fit_transform(df_catboost[column].astype(str))\n",
    "    label_encoders[column] = le  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одно применение k-means и StandardScaler к 'age','gender', 'topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 20 , random_state=42).fit((df_catboost[['age','gender', 'topic']]))\n",
    "scaler = StandardScaler()\n",
    "KMeans_scaled = scaler.fit_transform((df_catboost[['age','gender', 'topic']]))\n",
    "df_catboost['age_gender_topic_kmeans'] = pd.DataFrame(kmeans.predict(X=df_catboost[['age','gender', 'topic']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:37:29.079293Z",
     "iopub.status.busy": "2024-11-24T07:37:29.078167Z",
     "iopub.status.idle": "2024-11-24T07:37:29.360107Z",
     "shell.execute_reply": "2024-11-24T07:37:29.359014Z",
     "shell.execute_reply.started": "2024-11-24T07:37:29.079232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select only numeric columns for conversion\n",
    "numeric_columns = df_catboost.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Convert only numeric columns to float32\n",
    "df_catboost[numeric_columns] = df_catboost[numeric_columns].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем оценивать качество модели по метрике HitRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hitrate(y_true, y_pred_proba, threshold=0.5):\n",
    "     y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "     return (y_pred == y_true).mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T07:37:30.956889Z",
     "iopub.status.busy": "2024-11-24T07:37:30.956496Z",
     "iopub.status.idle": "2024-11-24T07:37:31.690139Z",
     "shell.execute_reply": "2024-11-24T07:37:31.688699Z",
     "shell.execute_reply.started": "2024-11-24T07:37:30.956854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Preparing data for training\n",
    "X = df_catboost.drop(['target', 'timestamp', 'user_id', 'post_id'], axis=1)\n",
    "y = df_catboost['target']\n",
    "user_ids = df_catboost['user_id']\n",
    "\n",
    "# Splitting data into training and testing samples\n",
    "X_train, X_test, y_train, y_test, user_train, user_test = train_test_split(X, y, user_ids, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение CatBoostClassifier модели с использованием кросс-валидации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.830659Z",
     "iopub.status.idle": "2024-11-24T07:18:30.831239Z",
     "shell.execute_reply": "2024-11-24T07:18:30.830987Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.830959Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import catboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "def train_catboost(X_train, y_train, param_dist=None, random_state=42):\n",
    "    \n",
    "    catboost_model = CatBoostClassifier(loss_function='Logloss', \n",
    "                                        verbose=0, \n",
    "                                        random_state=random_state,             \n",
    "                                       )\n",
    "    param_grid = {\n",
    "            'depth': [4, 6, 8],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'iterations': [100, 200],\n",
    "            'l2_leaf_reg': [1, 3, 5],\n",
    "        }\n",
    "\n",
    "    best_hitrate = 0\n",
    "    best_model = None\n",
    "    \n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        \n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "        grid_search = GridSearchCV(catboost_model, param_grid, scoring='roc_auc', cv=5, n_jobs=1)\n",
    "        print(\"Starting GridSearchCV...\")\n",
    "        grid_search.fit(X_train_fold, y_train_fold)\n",
    "        print(\"Finished GridSearchCV.\")\n",
    "        \n",
    "        # Оценка HitRate на валидационной выборке\n",
    "        y_val_pred_proba = grid_search.predict_proba(X_val_fold)[:, 1]\n",
    "        hitrate = calculate_hitrate(y_val_fold, y_val_pred_proba)\n",
    "        \n",
    "        if hitrate > best_hitrate:\n",
    "            best_hitrate = hitrate\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.832679Z",
     "iopub.status.idle": "2024-11-24T07:18:30.833223Z",
     "shell.execute_reply": "2024-11-24T07:18:30.832974Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.832947Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_final = X_train.iloc[:1000000]\n",
    "y_train_final = y_train.iloc[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.834605Z",
     "iopub.status.idle": "2024-11-24T07:18:30.835134Z",
     "shell.execute_reply": "2024-11-24T07:18:30.834892Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.834865Z"
    }
   },
   "outputs": [],
   "source": [
    "model = train_catboost(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение модели и фичей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.837562Z",
     "iopub.status.idle": "2024-11-24T07:18:30.838080Z",
     "shell.execute_reply": "2024-11-24T07:18:30.837869Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.837841Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_model('catboost_model', format=\"cbm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.841072Z",
     "iopub.status.idle": "2024-11-24T07:18:30.842333Z",
     "shell.execute_reply": "2024-11-24T07:18:30.842128Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.842101Z"
    }
   },
   "outputs": [],
   "source": [
    "df_for_saving = df_catboost.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T07:18:30.845854Z",
     "iopub.status.idle": "2024-11-24T07:18:30.846450Z",
     "shell.execute_reply": "2024-11-24T07:18:30.846215Z",
     "shell.execute_reply.started": "2024-11-24T07:18:30.846185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "    \"postgres.lab.karpov.courses:6432/startml\"\n",
    ")\n",
    "\n",
    "df_for_saving.to_sql('ulyanas_astrovas_features', engine, if_exists='append', chunksize=1000)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
